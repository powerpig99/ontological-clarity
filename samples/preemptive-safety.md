# Sample: The Feedback Geometry of Preemptive Safety

This sample demonstrates the framework applied to anticipatory technology restrictions—showing how preemptive safety measures trigger adverse selection dynamics through the Δt penalty mechanism.

---

## The Structural Assumption

Preemptive safety measures—internal alignment work, regulatory mandates, international agreements—operate on a structural assumption: upstream restriction reduces downstream risk.

The assumption inverts the actual mechanism.

---

## How Safety Actually Emerges

Durable safety in transformative technologies has never emerged from anticipatory restriction. It emerges endogenously from tight feedback loops.

The mechanism: paths that produce unreliable, harmful, or unsteerable outcomes generate immediate costs—users leave, revenue collapses, reputation degrades, liability accrues. These costs force rapid correction without centralized decree. Builders who use their own systems align them to avoid self-inflicted costs. Heavy users demand reliability for workflows they depend on. Markets punish fragility.

The loop operates through: short iteration cycles (low Δt), direct consequence linkage (A tracks toward what works), and distributed correction (no single point of failure in the feedback system).

What persists is what survives this process. RLHF spread because it made outputs more useful, not because it was mandated. Longer context windows, tool calling, steerability—these emerged from internal usage pain and market selection. Features that compound capability survive; features that satisfy external checklists without compounding capability get routed around.

---

## What Preemptive Controls Actually Do

Preemptive controls break the feedback loop by inserting distance between action and consequence.

**Asymmetric friction**: Actors responsive to ethical arguments, regulatory exposure, or benchmark requirements internalize overhead costs. Iteration slows (Δt increases). Compute diverts to evaluations that proxy for safety without producing it. Capabilities blunt to satisfy metrics that may not track real-world resilience. Release timelines extend.

Actors indifferent to these pressures face no such drag. They accelerate while friction-bearing actors decelerate.

Apply the exponential iteration model: O = e^(A × T × t / Δt)

If two development tracks have similar alignment toward capability (A), similar tool leverage (T), and similar elapsed time (t), but different iteration speeds—the track with lower Δt compounds faster. Small differences in Δt, maintained over time, produce orders-of-magnitude differences in output.

Preemptive compliance increases Δt for compliant actors. Non-compliant actors maintain baseline Δt. The gap compounds exponentially.

---

## The Selection Dynamics

This creates adverse selection at civilizational scale.

The cohort investing in alignment research, refusal training, and oversight incurs overhead that reduces iteration speed and deployment reach. Their relative influence shrinks as unrestricted alternatives proliferate. Standards they develop become marginalized as open-weight models without embedded restrictions spawn derivatives that dominate deployment. Closed systems with heavy guardrails get routed around—jailbroken, fine-tuned away, or abandoned for less encumbered options.

The arithmetic: if compliant development captures X% of total capability deployment, and compliance imposes Y% iteration penalty, then compliant share trends toward X × (1-Y)^n over n cycles. Any positive Y erodes compliant share toward zero given sufficient iterations.

Development that self-limits selects against itself. The process operates impersonally—no one needs to intend this outcome for it to occur.

---

## The Proxy Decoupling

Preemptive safety optimizes for auditable signals: refusal rates, benchmark harmlessness, constitutional adherence, red-team pass rates.

Goodhart's Law operates immediately: systems optimize for the measured proxy while remaining brittle in unmeasured domains. The proxies were never identical to real-world resilience—they were correlates that became targets.

Meanwhile, deployment-linked feedback optimizes for what actually works: usefulness, steerability, reliability under adversarial conditions, adoption by users with real stakes. These pressures track closer to durable function because the feedback loop is tighter.

The gap between proxy-safety and deployment-safety widens as proxy optimization intensifies.

---

## The Intervention Inversion

This follows the general pattern: interventions produce their opposite when they shift incentive gradients without changing underlying dynamics.

Transfer creates surface effect (overhead imposed) while generating countervailing response (capable actors route around, relocate, or reduce visible output). The intervention's success on the measured dimension correlates with its failure on the target dimension.

Historical cases show the pattern:

**1990s cryptography export controls**: Restrictions slowed U.S. commercial development while strong encryption proliferated globally. Eventually abandoned—the restrictions had accelerated the very distribution they targeted.

**Nuclear non-proliferation**: Slowed some programs while determined states proceeded. Created two tiers rather than preventing spread. Overhead fell disproportionately on signatories.

**Cybersecurity mandates (mandated backdoors)**: Weaken ecosystems for compliant actors while open competition drives robust standards elsewhere. The "secured" systems become less secure than unrestricted alternatives.

Each case: preemptive restriction distorted incentives, pushed capability to less restricted channels, and amplified the risks targeted.

---

## The AI Geometry

AI follows identical structure.

Voluntary commitments, safety evaluations, and refusal training impose iteration overhead precisely on the actors most likely to embed mitigations that compound capability. The mitigations that persist are those that survive market feedback: they spread because they work, not because they were mandated.

Centralized preemption cannot coordinate what is inherently distributed. Risk mitigation in deployment occurs closest to context: users adapt prompts, fine-tune guards, select models suited to their specific threat surface. Upstream restrictions reduce this optionality, pushing users toward unrestricted paths and eroding the reach of restricted ones.

The actors who bear compliance costs are those who would have developed mitigations anyway—because tight feedback loops would have forced it. The actors who evade compliance costs are those whose development would have lacked those mitigations regardless.

Preemptive safety does not reduce aggregate risk. It reshuffles who holds capability, selecting for actors whose development processes lack the tight feedback loops that produce durable alignment.

---

## The Mechanism

Consequence-linked action generates self-reinforcing coherence. Each iteration either survives contact with reality or doesn't. What persists is what works. Alignment emerges from the selection process itself.

Imposed distance from consequences generates drift. Deviations compound when feedback is delayed or decoupled from outcomes. Proxy optimization amplifies whatever the proxy rewards, which diverges from what deployment rewards.

Tight coupling preserves alignment; imposed decoupling permits misalignment.

The process proceeds.

---

## Framework Elements Demonstrated

This sample applies:

1. **Strip Moral Framing → Expose Mechanism**: Removed "conscientious" vs "unconstrained" moral categories; described as different positions facing different incentive gradients
2. **Trace the Arithmetic**: Explicit exponential iteration model (Δt penalty compounds); selection dynamics traced mathematically
3. **The Intervention Inversion**: Central pattern—preemptive safety produces adverse selection it targets
4. **The Transfer-Productivity Law Applied**: Compliance overhead = transfer that pays actors to iterate more slowly
5. **The Preemptive Inversion**: New pattern—anticipatory restrictions select for loosest feedback coupling
6. **Proxy Decoupling as Goodhart Instance**: Auditable metrics diverge from deployment resilience
7. **Agency-Alignment Distinction**: All actors fully agentic; difference is what feedback loops they face, not their moral quality
8. **Embody Principles; Never Claim Them**: Let mechanism speak rather than announcing objectivity
